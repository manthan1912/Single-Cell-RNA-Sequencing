{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4237eae",
   "metadata": {},
   "source": [
    "### Installing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46534ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b5fc6c",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd895fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b8050",
   "metadata": {},
   "source": [
    "#### Importing training and testing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f230121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "train_df = pd.read_csv('Data/data_tr.txt',delimiter=\"\\t\", header=None)\n",
    "test_df = pd.read_csv('Data/data_ts.txt',delimiter=\"\\t\", header=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c4268c",
   "metadata": {},
   "source": [
    "#### Defining true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f502e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = []\n",
    "with open('Data/labels_ts.txt','r') as f:\n",
    "    reader = csv.reader(f, dialect='excel',delimiter= '\\t')\n",
    "    for i in reader:\n",
    "        labs.append(i)\n",
    "true_labels = [val for sublist in labs for val in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6491398",
   "metadata": {},
   "source": [
    "#### Finding high correlation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89eb5bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:10: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "<timed exec>:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "<timed exec>:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with more than or equal to 0.8 correlation:  [1099, 1113, 1875, 2093, 2446, 2620, 2937, 3141, 4431, 9586, 10778]\n",
      "Wall time: 1h 14min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This cell takes a lot of time as it calculates correlation for 13k samples.\n",
    "# I have divided the dataframe into 3 parts and took correlation individually to sped up the execution.\n",
    "\n",
    "df_1 = train_df.iloc[:,0:5000]\n",
    "df_2 = train_df.iloc[:,5000:10000]\n",
    "df_3 = train_df.iloc[:,10000:]\n",
    "\n",
    "\n",
    "corr_1 = df_1.corr()\n",
    "upper_triangle_1 = corr_1.where(np.triu(np.ones(corr_1.shape),k=1).astype(np.bool))\n",
    "to_drop_1 = [column for column in upper_triangle_1.columns if any(upper_triangle_1[column] > 0.8)]\n",
    "\n",
    "corr_2 = df_2.corr()\n",
    "upper_triangle_2 = corr_2.where(np.triu(np.ones(corr_2.shape),k=1).astype(np.bool))\n",
    "to_drop_2 = [column for column in upper_triangle_2.columns if any(upper_triangle_2[column] > 0.8)]\n",
    "\n",
    "corr_3 = df_3.corr()\n",
    "upper_triangle_3 = corr_3.where(np.triu(np.ones(corr_3.shape),k=1).astype(np.bool))\n",
    "to_drop_3 = [column for column in upper_triangle_3.columns if any(upper_triangle_3[column] > 0.8)]\n",
    "\n",
    "cols_to_drop = to_drop_1 + to_drop_2 + to_drop_3\n",
    "print(\"Features with more than or equal to 0.8 correlation: \",cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5736f09a",
   "metadata": {},
   "source": [
    "#### Dropping columns having high correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9186505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# From the above cell, we got the [1099, 1113, 1875, 2093, 2446, 2620, 2937, 3141, 4431, 9586, 10778] columns as highly correlated\n",
    "\n",
    "# cols_to_drop = [1099, 1113, 1875, 2093, 2446, 2620, 2937, 3141, 4431, 9586, 10778]\n",
    "\n",
    "new_train_df = train_df.drop(cols_to_drop,axis = 1)\n",
    "new_test_df = test_df.drop(cols_to_drop,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f69f6",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a9f9c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler(feature_range=(0, 10))\n",
    "norm_fit = norm.fit(new_train_df)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm_fit.transform(new_train_df)\n",
    "\n",
    "X_test_norm = norm.transform(new_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30348607",
   "metadata": {},
   "source": [
    "#### Dimensionality reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b003ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca_100 = PCA(n_components=100, random_state=0)\n",
    "pca_100_fit = pca_100.fit(X_train_norm)\n",
    "X_train_norm_100 = pca_100_fit.transform(X_train_norm)\n",
    "X_test_norm_100 = pca_100_fit.transform(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6983c",
   "metadata": {},
   "source": [
    "#### Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f0f64595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adjusted rand score is:  0.9034293886247964\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=0)\n",
    "model_birch = Birch(n_clusters=16,threshold=3.5,branching_factor=400)\n",
    "model_birch_fit = model_birch.fit(X_train_norm_100)\n",
    "# prediction = model_birch_fit.predict(X_train_norm_100)\n",
    "\n",
    "prediction = model_birch_fit.predict(X_test_norm_100)\n",
    "print(\"The adjusted rand score is: \",adjusted_rand_score(true_labels,prediction.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db240c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
